{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Load.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOihrAKvtUEJD32SY2jCtzy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaviSriTejaKuriseti/YogaPoseDetection/blob/main/Load.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH3dmhuEJ0wS"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io,transform\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.io import read_image\n",
        "import glob\n",
        "import os\n",
        "from IPython.display import Image\n",
        "import sys\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,data_csv,train=True,to_encode=True,img_transform=None):\n",
        "        \"\"\"\n",
        "        Dataset init function\n",
        "        \n",
        "        INPUT:\n",
        "        data_csv: Path to csv file containing [data, labels]\n",
        "        train: \n",
        "            True: if the csv file has [labels,data] (Train data and Public Test Data) \n",
        "            False: if the csv file has only [data] and labels are not present.\n",
        "        img_transform: List of preprocessing operations need to performed on image. \n",
        "        \"\"\"\n",
        "        self.data_csv = data_csv\n",
        "        self.img_transform = img_transform\n",
        "        self.is_train = train\n",
        "        self.le=preprocessing.LabelEncoder()\n",
        "        self.fit_to_encode=to_encode\n",
        "\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        \"\"\"Returns total number of samples in the dataset\"\"\"\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Loads image of the given index and performs preprocessing.\n",
        "        \n",
        "        INPUT: \n",
        "        idx: index of the image to be loaded.\n",
        "        \n",
        "        OUTPUT:\n",
        "        sample: dictionary with keys images (Tensor of shape [1,C,H,W]) and labels (Tensor of labels [1]).\n",
        "        \"\"\"\n",
        "        data=pd.read_csv(self.data_csv, header=None)        \n",
        "        img_path=data.iloc[idx, 0]\n",
        "        image=read_image(img_path)\n",
        "        image_labels=data.iloc[:,1]        \n",
        "        if self.is_train:\n",
        "            if(self.fit_to_encode):\n",
        "              self.le.fit(image_labels)\n",
        "            labels=self.le.transform(image_labels).astype(int)\n",
        "            label = labels[idx]\n",
        "        else:\n",
        "            label=-1\n",
        "        \n",
        "        image = self.img_transform(image) \n",
        "        print(image.size)       \n",
        "        sample = (image,label)\n",
        "        return sample\n",
        "\n",
        "\n",
        "\n",
        "def load_train_data(train_data):\n",
        "  BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
        "  NUM_WORKERS = 20 # Number of threads to be used for image loading. Adjust accordingly.\n",
        "\n",
        "  img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
        "\n",
        "  # Train DataLoader\n",
        "  # train_data = \"\" # Path to train csv file\n",
        "  train_dataset = ImageDataset(data_csv = train_data, train=True,to_encode=True,img_transform=img_transforms)\n",
        "  train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE,shuffle=False, num_workers = NUM_WORKERS)\n",
        "  return train_loader\n",
        "\n",
        "\n",
        "def load_test_data_with_labels(test_data):\n",
        "\n",
        "  BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
        "  NUM_WORKERS = 20 # Number of threads to be used for image loading. Adjust accordingly.\n",
        "\n",
        "  img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
        "  # Test DataLoader\n",
        "  # test_data = \"\" # Path to test csv file\n",
        "  test_dataset = ImageDataset(data_csv = test_data, train=True,to_encode=False,img_transform=img_transforms)\n",
        "  test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE,shuffle=False, num_workers = NUM_WORKERS)\n",
        "  return test_loader\n",
        "\n",
        "\n",
        "\n",
        "def load_test_data_without_labels(test_data):\n",
        "  BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
        "  NUM_WORKERS = 20 # Number of threads to be used for image loading. Adjust accordingly.\n",
        "\n",
        "  img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
        "\n",
        "  # Test DataLoader\n",
        "  # test_data = \"\" # Path to test csv file\n",
        "  test_dataset = ImageDataset(data_csv = test_data, train=False,to_encode=False,img_transform=img_transforms)\n",
        "  test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE,shuffle=False, num_workers = NUM_WORKERS)\n",
        "  return test_loader\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}